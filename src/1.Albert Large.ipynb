{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Albert Large.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4MYEP33bH2pJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"status":"ok","timestamp":1593884285459,"user_tz":300,"elapsed":1248,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}},"outputId":"8ac5bd7a-4fbd-44a3-ca8d-dca1b00236a5"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Jul  4 17:38:05 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hi4iWotlgiGq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"status":"ok","timestamp":1593884285460,"user_tz":300,"elapsed":1229,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}},"outputId":"0235bbf0-076d-46ec-e32b-ce459a40ea3c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/Tweet Sentiment Extraction Final"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Tweet Sentiment Extraction Final\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9rVu1fCJA_a_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"ok","timestamp":1593884287885,"user_tz":300,"elapsed":3637,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}},"outputId":"6873ea10-8442-41ba-c25e-36270336168a"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.0rc4)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"61JjdybxSnaa","colab_type":"text"},"source":["# Utils"]},{"cell_type":"code","metadata":{"id":"GdTtQZmuSm3r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884288021,"user_tz":300,"elapsed":3746,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["import os\n","import random\n","\n","import torch\n","import numpy as np\n","\n","class utils:\n","  def seed_everything(seed):\n","      random.seed(seed)\n","      os.environ['PYTHONHASHSEED'] = str(seed)\n","      torch.manual_seed(seed)\n","      torch.backends.cudnn.deterministic = True\n","      torch.backends.cudnn.benchmark = False\n","      np.random.seed(seed)\n","\n","\n","  def token_level_to_char_level(text, offsets, preds):\n","      probas_char = np.zeros(len(text))\n","      for i, offset in enumerate(offsets):\n","          if offset[0] or offset[1]:\n","              probas_char[offset[0]:offset[1]] = preds[i]\n","\n","      return probas_char\n","\n","\n","  def jaccard(str1, str2):\n","      \"\"\"Original metric implementation.\"\"\"\n","      a = set(str1.lower().split())\n","      b = set(str2.lower().split())\n","      c = a.intersection(b)\n","      return float(len(c)) / (len(a) + len(b) - len(c))\n","\n","\n","  def get_best_start_end_idx(start_logits, end_logits,\n","                            orig_start, orig_end):\n","      \"\"\"Return best start and end indices following BERT paper.\"\"\"\n","      best_logit = -np.inf\n","      best_idxs = None\n","      start_logits = start_logits[orig_start:orig_end + 1]\n","      end_logits = end_logits[orig_start:orig_end + 1]\n","      for start_idx, start_logit in enumerate(start_logits):\n","          for end_idx, end_logit in enumerate(end_logits[start_idx:]):\n","              logit_sum = start_logit + end_logit\n","              if logit_sum > best_logit:\n","                  best_logit = logit_sum\n","                  best_idxs = (orig_start + start_idx,\n","                              orig_start + start_idx + end_idx)\n","      return best_idxs\n","\n","\n","  def calculate_jaccard(original_tweet, target_string,\n","                        start_logits, end_logits,\n","                        orig_start, orig_end,\n","                        offsets, \n","                        verbose=False):\n","      \"\"\"Calculates final Jaccard score using predictions.\"\"\"\n","      start_idx, end_idx = get_best_start_end_idx(\n","          start_logits, end_logits, orig_start, orig_end)\n","\n","      filtered_output = ''\n","      for ix in range(start_idx, end_idx + 1):\n","          filtered_output += original_tweet[offsets[ix][0]:offsets[ix][1]]\n","          if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n","              filtered_output += ' '\n","\n","      # Return orig tweet if it has less then 2 words\n","      if len(original_tweet.split()) < 2:\n","          filtered_output = original_tweet\n","\n","      if len(filtered_output.split()) == 1:\n","          filtered_output = filtered_output.replace('!!!!', '!')\n","          filtered_output = filtered_output.replace('..', '.')\n","          filtered_output = filtered_output.replace('...', '.')\n","\n","      filtered_output = filtered_output.replace('ïï', 'ï')\n","      filtered_output = filtered_output.replace('¿¿', '¿')\n","\n","      jac = jaccard(target_string.strip(), filtered_output.strip())\n","      return jac, filtered_output\n","\n","\n","  class AverageMeter:\n","      \"\"\"Computes and stores the average and current value.\"\"\"\n","\n","      def __init__(self):\n","          self.reset()\n","\n","      def reset(self):\n","          self.val = 0\n","          self.avg = 0\n","          self.sum = 0\n","          self.count = 0\n","\n","      def update(self, val, n=1):\n","          self.val = val\n","          self.sum += val * n\n","          self.count += n\n","          self.avg = self.sum / self.count\n","\n","  class EarlyStopping:\n","    def __init__(self, patience=7, mode=\"max\", delta=0.001):\n","      self.patience = patience\n","      self.counter = 0\n","      self.mode = mode\n","      self.best_score = None\n","      self.early_stop = False\n","      self.delta = delta\n","      if self.mode == \"min\":\n","          self.val_score = np.Inf\n","      else:\n","          self.val_score = -np.Inf\n","\n","    def __call__(self, epoch_score, model, model_path):\n","\n","      if self.mode == \"min\":\n","          score = -1.0 * epoch_score\n","      else:\n","          score = np.copy(epoch_score)\n","\n","      if self.best_score is None:\n","          self.best_score = score\n","          self.save_checkpoint(epoch_score, model, model_path)\n","      elif score < self.best_score + self.delta:\n","          self.counter += 1\n","          print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n","          if self.counter >= self.patience:\n","              self.early_stop = True\n","      else:\n","          self.best_score = score\n","          self.save_checkpoint(epoch_score, model, model_path)\n","          self.counter = 0\n","\n","    def save_checkpoint(self, epoch_score, model, model_path):\n","      if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n","          print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n","          torch.save(model.state_dict(), model_path)\n","      self.val_score = epoch_score"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"liJmxoHfc8Tu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884288023,"user_tz":300,"elapsed":3734,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["# !pip install protobuf\n","# !wget https://raw.githubusercontent.com/google/sentencepiece/master/python/sentencepiece_pb2.py\n","import sys\n","sys.path.insert(0, './input/sentencepiece_pb2/')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Lg8cr5OaoIA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884288023,"user_tz":300,"elapsed":3722,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["import sentencepiece as spm\n","import sentencepiece_pb2\n","\n","class EncodedText:\n","  def __init__(self, ids, offsets):\n","    self.ids = ids\n","    self.offsets = offsets\n","\n","class SentencePieceTokenizer:\n","  def __init__(self, model_path):\n","    self.sp = spm.SentencePieceProcessor()\n","    self.sp.load(os.path.join(model_path, 'spiece.model'))\n","  \n","  def encode(self, sentence):\n","    spt = sentencepiece_pb2.SentencePieceText()\n","    spt.ParseFromString(self.sp.encode_as_serialized_proto(sentence))\n","    offsets = []\n","    tokens = []\n","    for piece in spt.pieces:\n","      tokens.append(piece.id)\n","      offsets.append((piece.begin, piece.end))\n","    return EncodedText(tokens, offsets)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABIyIgoL9jyd","colab_type":"text"},"source":["# Config"]},{"cell_type":"code","metadata":{"id":"XhoYjBVPvIFK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884288024,"user_tz":300,"elapsed":3712,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["MODEL_PATHS = {\n","    'albert-base-v2': './input/albert-configs/albert-base-v2',\n","    'albert-large-v2': './input/albert-configs/albert-large-v2',\n","    'bert-base-uncased': './input/bert-configs/uncased_L-12_H-768_A-12',\n","    'bert-large-uncased-whole-word-masking-finetuned-squad': './input/bert-configs/wwm_uncased_L-24_H-1024_A-16',\n","    'distilbert': './input/albert-configs/distilbert',\n","}"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"7j70FwJDkO8K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884289643,"user_tz":300,"elapsed":5317,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["import tokenizers\n","import torch\n","import transformers\n","\n","class config:\n","\n","  # Name of model\n","  SELECTED_MODEL = 'albert-large-v2'\n","\n","  # Model Paths\n","  TOKENIZER_PATH = MODEL_PATHS[SELECTED_MODEL]\n","  PRETRAINED_MODEL_PATH = MODEL_PATHS[SELECTED_MODEL]\n","  MODEL_CONFIG_PATH = MODEL_PATHS[SELECTED_MODEL]\n","  LOWERCASE = True\n","\n","  # Data Paths\n","  TRAIN_FILE = './input/tweet-sentiment-extraction/train_folds.csv' \n","  TEST_FILE = './input/tweet-sentiment-extraction/test.csv'\n","  SAMPLE_SUBMISSION_FILE = './input/tweet-sentiment-extraction/sample_submission.csv' \n","  SAVE_WEIGHTS_PATH = './output/Albert Large'\n","  FINAL_SUBMISSION_FILE = './output/Albert Large'   \n","\n","  # Model params\n","  SEED = 25\n","  N_FOLDS = 5\n","  EPOCHS = 5\n","  LEARNING_RATE = 4e-5\n","  PATIENCE = 2\n","  EARLY_STOPPING_DELTA = 0.001\n","  TRAIN_BATCH_SIZE = 32\n","  VALID_BATCH_SIZE = 16\n","  MAX_LEN = 128  \n","  \n","  HIDDEN_SIZE = 1024\n","  N_LAST_HIDDEN = 24\n","  HIGH_DROPOUT = 0.5\n","  SOFT_ALPHA = 0.6\n","  WARMUP_RATIO = 0.25\n","  WEIGHT_DECAY = 0.001\n","  USE_SWA = False\n","  SWA_RATIO = 0.9\n","  SWA_FREQ = 30"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KN-LC6x_9znO","colab_type":"text"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"vNRLRXBdr5zu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884289645,"user_tz":300,"elapsed":5300,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["def create_tokenizer_and_tokens():\n","  # Check If Word Is In A String - https://stackoverflow.com/questions/5319922/python-check-if-word-is-in-a-string\n","  if \"albert\" in config.SELECTED_MODEL:\n","    TOKENIZER = SentencePieceTokenizer(config.TOKENIZER_PATH)\n","    TOKENS = {'cls': 2,\n","              'sep': 3,\n","              'pad': 0}  \n","  else:\n","    TOKENIZER = tokenizers.BertWordPieceTokenizer(config.TOKENIZER_PATH+'/vocab.txt', lowercase=config.LOWERCASE)\n","    TOKENS = {'cls': TOKENIZER.token_to_id('[CLS]'),\n","              'sep': TOKENIZER.token_to_id('[SEP]'),\n","              'pad': TOKENIZER.token_to_id('[PAD]')}\n","\n","  for sentiment in ['positive', 'negative', 'neutral']:\n","    ids = TOKENIZER.encode(sentiment).ids\n","    TOKENS[sentiment] = ids[0] if ids[0] != TOKENS['cls'] else ids[1]\n","  \n","  return TOKENIZER, TOKENS\n","\n","TOKENIZER, TOKENS = create_tokenizer_and_tokens()"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"hctcW8Nq9zE8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884289801,"user_tz":300,"elapsed":5430,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["import numpy as np\n","import torch\n","\n","def jaccard_array(a, b):\n","    \"\"\"Calculates Jaccard on arrays.\"\"\"\n","    a = set(a)\n","    b = set(b)\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))\n","\n","def process_data(tweet, selected_text, sentiment,\n","                 tokenizer, max_len):\n","    \"\"\"Preprocesses one data sample and returns a dict\n","    with targets and other useful info.\n","    \"\"\"\n","    len_sel_text = len(selected_text)\n","    # Get selected_text start and end idx\n","    idx_0 = None\n","    idx_1 = None\n","    for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n","      if tweet[ind: ind+len_sel_text] == selected_text:\n","        idx_0 = ind\n","        idx_1 = ind + len_sel_text - 1\n","        break\n","\n","    # Assign 1 as target for each char in sel_text\n","    char_targets = [0] * len(tweet)\n","    if idx_0 is not None and idx_1 is not None:\n","        for ct in range(idx_0, idx_1 + 1):\n","            char_targets[ct] = 1\n","\n","    # Refer example - https://github.com/huggingface/tokenizers\n","    tokenized_tweet = tokenizer.encode(tweet)\n","    # Vocab ids\n","    input_ids_original = tokenized_tweet.ids\n","    # Start and end char\n","    tweet_offsets = tokenized_tweet.offsets\n","\n","    # Getting rid of special tokens\n","    if input_ids_original[0] == TOKENS[\"cls\"]: \n","      input_ids_original = input_ids_original[1:-1] \n","      tweet_offsets = tweet_offsets[1:-1]\n","\n","    # Get ids within tweet of words that have target char\n","    target_ids = []\n","    for i, (offset_0, offset_1) in enumerate(tweet_offsets):\n","        if sum(char_targets[offset_0:offset_1]) > 0:\n","            target_ids.append(i)\n","\n","    targets_start = target_ids[0]\n","    targets_end = target_ids[-1]\n","\n","    # Soft Jaccard labels\n","    # ----------------------------------\n","    n = len(input_ids_original)\n","    sentence = np.arange(n)\n","    answer = sentence[targets_start:targets_end + 1]\n","\n","    start_labels = np.zeros(n)\n","    for i in range(targets_end + 1):\n","        jac = jaccard_array(answer, sentence[i:targets_end + 1])\n","        start_labels[i] = jac + jac ** 2\n","    start_labels = (1 - config.SOFT_ALPHA) * start_labels / start_labels.sum()\n","    start_labels[targets_start] += config.SOFT_ALPHA\n","\n","    end_labels = np.zeros(n)\n","    for i in range(targets_start, n):\n","        jac = jaccard_array(answer, sentence[targets_start:i + 1])\n","        end_labels[i] = jac + jac ** 2\n","    end_labels = (1 - config.SOFT_ALPHA) * end_labels / end_labels.sum()\n","    end_labels[targets_end] += config.SOFT_ALPHA\n","\n","    start_labels = [0, 0, 0] + list(start_labels) + [0]\n","    end_labels = [0, 0, 0] + list(end_labels) + [0]\n","    # ----------------------------------\n","\n","    # Input for ALBERT/BERT\n","    input_ids = [TOKENS[\"cls\"], TOKENS[sentiment], TOKENS[\"sep\"]] + input_ids_original + [TOKENS[\"sep\"]]\n","    token_type_ids = [0, 0, 0] + [1] * (len(input_ids_original) + 1)\n","    # Mask of input without padding\n","    mask = [1] * len(token_type_ids)\n","    # Start and end char ids for each word including new tokens\n","    tweet_offsets = [(0, 0)] * 3 + tweet_offsets + [(0, 0)]\n","    # Ids within tweet of words that have target char including new tokens\n","    targets_start += 3\n","    targets_end += 3\n","\n","    # Input padding: new mask, token type ids, tweet offsets\n","    padding_len = max_len - len(input_ids)\n","    if padding_len > 0:\n","        input_ids = input_ids + ([1] * padding_len)\n","        mask = mask + ([0] * padding_len)\n","        token_type_ids = token_type_ids + ([0] * padding_len)\n","        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_len)\n","        start_labels = start_labels + ([0] * padding_len)\n","        end_labels = end_labels + ([0] * padding_len)\n","    else:\n","        input_ids = input_ids[:max_len]\n","        mask = mask[:max_len]\n","        token_type_ids = token_type_ids[:max_len]\n","        tweet_offsets = tweet_offsets[:max_len]\n","        start_labels = start_labels[:max_len]\n","        end_labels = end_labels[:max_len]\n","\n","    return {'ids': input_ids,\n","            'mask': mask,\n","            'token_type_ids': token_type_ids,\n","            'start_labels': start_labels,\n","            'end_labels': end_labels,\n","            'orig_tweet': tweet,\n","            'orig_selected': selected_text,\n","            'sentiment': sentiment,\n","            'offsets': tweet_offsets}\n","\n","\n","class TweetDataset:\n","    def __init__(self, tweets, sentiments, selected_texts):\n","        self.tweets = tweets\n","        self.sentiments = sentiments\n","        self.selected_texts = selected_texts\n","        self.max_len = config.MAX_LEN\n","        self.tokenizer = TOKENIZER\n","\n","    def __len__(self):\n","        return len(self.tweets)\n","\n","    def __getitem__(self, item):\n","        \"\"\"Returns preprocessed data sample as dict with\n","        data converted to tensors.\n","        \"\"\"\n","        data = process_data(self.tweets[item],\n","                            self.selected_texts[item],\n","                            self.sentiments[item],\n","                            self.tokenizer,\n","                            self.max_len)\n","\n","        return {'ids': torch.tensor(data['ids'], dtype=torch.long),\n","                'mask': torch.tensor(data['mask'], dtype=torch.long),\n","                'token_type_ids': torch.tensor(data['token_type_ids'],dtype=torch.long),\n","                'start_labels': torch.tensor(data['start_labels'],dtype=torch.float),\n","                'end_labels': torch.tensor(data['end_labels'],dtype=torch.float),\n","                'orig_tweet': data['orig_tweet'],\n","                'orig_selected': data['orig_selected'],\n","                'sentiment': data['sentiment'],\n","                'offsets': torch.tensor(data['offsets'], dtype=torch.long)}\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_o6eBo0d949L","colab_type":"text"},"source":["# Models"]},{"cell_type":"code","metadata":{"id":"DcY2clsXr1pM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884289802,"user_tz":300,"elapsed":5420,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["TRANSFORMERS = {   \n","    'albert-base-v2': (transformers.AlbertModel, transformers.AlbertConfig),\n","    'albert-large-v2': (transformers.AlbertModel, transformers.AlbertConfig),\n","    'bert-base-uncased': (transformers.BertModel, transformers.BertConfig),\n","    'bert-large-uncased-whole-word-masking-finetuned-squad': (transformers.BertModel, transformers.BertConfig),\n","    'distilbert': (transformers.DistilBertModel, transformers.DistilBertConfig)\n","}\n","\n","MODEL_CLASS, CONFIG_CLASS = TRANSFORMERS[config.SELECTED_MODEL]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cdk53GpY98aa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884289802,"user_tz":300,"elapsed":5406,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["class TweetModel(transformers.BertPreTrainedModel):\n","    def __init__(self, conf):\n","        super(TweetModel, self).__init__(conf)\n","        self.transformer = MODEL_CLASS.from_pretrained(config.PRETRAINED_MODEL_PATH, config=conf)\n","        self.high_dropout = torch.nn.Dropout(config.HIGH_DROPOUT)\n","        self.classifier = torch.nn.Linear(config.HIDDEN_SIZE * 2, 2)\n","\n","        torch.nn.init.normal_(self.classifier.weight, std=0.02)\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        # sequence_output of N_LAST_HIDDEN + Embedding states\n","        # (N_LAST_HIDDEN + 1, batch_size, num_tokens, 768)\n","        _, _, out = self.transformer(\n","            ids, attention_mask=mask, token_type_ids=token_type_ids)\n","        out = torch.stack(\n","            tuple(out[-i - 1] for i in range(config.N_LAST_HIDDEN)), dim=0)\n","        out_mean = torch.mean(out, dim=0)\n","        out_max, _ = torch.max(out, dim=0)\n","        out = torch.cat((out_mean, out_max), dim=-1)\n","\n","        # Multisample Dropout: https://arxiv.org/abs/1905.09788\n","        logits = torch.mean(torch.stack([\n","            self.classifier(self.high_dropout(out))\n","            for _ in range(5)\n","        ], dim=0), dim=0)\n","\n","        start_logits, end_logits = logits.split(1, dim=-1)\n","\n","        # (batch_size, num_tokens)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","\n","        return start_logits, end_logits\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-dr7pnc_0IW","colab_type":"text"},"source":["# Loss Function"]},{"cell_type":"code","metadata":{"id":"Lsn_Kq9d_5h8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884289803,"user_tz":300,"elapsed":5396,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["# outputs must be log-probabilities and labels must be probabilities \n","def loss_fn(start_logits, end_logits, start_labels, end_labels):\n","  logsoftmax = nn.LogSoftmax(dim=1)\n","  loss_fct = nn.KLDivLoss(reduction='batchmean')\n","  start_loss = loss_fct(logsoftmax(start_logits), start_labels)\n","  end_loss = loss_fct(logsoftmax(end_logits), end_labels)\n","  total_loss = (start_loss + end_loss)\n","  return total_loss"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zSAh_wfR_7sL","colab_type":"text"},"source":["# Training Function"]},{"cell_type":"code","metadata":{"id":"VJBMHMa2_9_M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884290012,"user_tz":300,"elapsed":5590,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["from tqdm.autonotebook import tqdm\n","\n","def train_fn(data_loader, model, optimizer, device, scheduler=None):\n","    \n","    # First thing we want to do is put the model in train mode\n","    model.train()\n","    \n","    # Check the AverageMeter class in utils class\n","    # Instantiate the AverageMeter class to print average loss & jaccard score\n","    losses = utils.AverageMeter()\n","    jaccards = utils.AverageMeter()\n","\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    for bi, d in enumerate(tk0):\n","        \n","        # Load data into variables\n","        ids = d[\"ids\"]\n","        mask = d[\"mask\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        start_labels = d[\"start_labels\"]\n","        end_labels = d[\"end_labels\"]\n","        orig_tweet = d[\"orig_tweet\"]\n","        orig_selected = d[\"orig_selected\"]\n","        sentiment = d[\"sentiment\"]\n","        offsets = d[\"offsets\"]\n","\n","        # Push the variables to GPU device\n","        # https://pytorch.org/docs/stable/tensor_attributes.html\n","        ids = ids.to(device, dtype=torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","        mask = mask.to(device, dtype=torch.long)\n","        start_labels = start_labels.to(device, dtype=torch.float)\n","        end_labels = end_labels.to(device, dtype=torch.float)\n","\n","        # Clear gradients w.r.t. parameters\n","        model.zero_grad()\n","        \n","        # Forward pass to get outputs\n","        outputs_start, outputs_end = model(\n","            ids=ids,\n","            mask=mask,\n","            token_type_ids=token_type_ids,\n","        )\n","\n","        # Calculate Loss: cross entropy loss\n","        loss = loss_fn(outputs_start, outputs_end, start_labels, end_labels)\n","        \n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","        \n","        # Updating parameters\n","        optimizer.step()\n","        scheduler.step()\n","\n","        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","        \n","        jaccard_scores = []\n","        for px, tweet in enumerate(orig_tweet):\n","            selected_tweet = orig_selected[px]\n","            tweet_sentiment = sentiment[px]\n","            jaccard_score, _ = calculate_jaccard_score(\n","                original_tweet=tweet,\n","                target_string=selected_tweet,\n","                sentiment_val=tweet_sentiment,\n","                idx_start=np.argmax(outputs_start[px, :]),\n","                idx_end=np.argmax(outputs_end[px, :]),\n","                offsets=offsets[px]\n","            )\n","            jaccard_scores.append(jaccard_score)\n","\n","        # Update and print\n","        losses.update(loss.item(), ids.size(0))\n","        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n","        tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtWWrFbOABfN","colab_type":"text"},"source":["# Evaluation Functions"]},{"cell_type":"code","metadata":{"id":"b7FWDGlBADKU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884290013,"user_tz":300,"elapsed":5573,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["def calculate_jaccard_score(\n","    original_tweet, \n","    target_string, \n","    sentiment_val, \n","    idx_start, \n","    idx_end, \n","    offsets,\n","    verbose=False):\n","    \n","    if idx_end < idx_start:\n","        idx_end = idx_start\n","    \n","    filtered_output  = \"\"\n","    for ix in range(idx_start, idx_end + 1):\n","        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n","        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n","            filtered_output += \" \"\n","\n","    if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n","        filtered_output = original_tweet\n","\n","    jac = utils.jaccard(target_string.strip(), filtered_output.strip())\n","    return jac, filtered_output\n","\n","\n","def eval_fn(data_loader, model, device):\n","  model.eval()\n","  losses = utils.AverageMeter()\n","  jaccards = utils.AverageMeter()\n","  \n","  with torch.no_grad():\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    for bi, d in enumerate(tk0):\n","      ids = d[\"ids\"]\n","      mask = d[\"mask\"]\n","      token_type_ids = d[\"token_type_ids\"]\n","      start_labels = d[\"start_labels\"]\n","      end_labels = d[\"end_labels\"]\n","      orig_tweet = d[\"orig_tweet\"]\n","      orig_selected = d[\"orig_selected\"]\n","      sentiment = d[\"sentiment\"]\n","      offsets = d[\"offsets\"]\n","\n","      ids = ids.to(device, dtype=torch.long)\n","      token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","      mask = mask.to(device, dtype=torch.long)\n","      start_labels = start_labels.to(device, dtype=torch.float)\n","      end_labels = end_labels.to(device, dtype=torch.float)\n","\n","      outputs_start, outputs_end = model(\n","          ids=ids,\n","          mask=mask,\n","          token_type_ids=token_type_ids\n","      )\n","      \n","      loss = loss_fn(outputs_start, outputs_end, start_labels, end_labels)\n","      outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","      outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","      jaccard_scores = []\n","      for px, tweet in enumerate(orig_tweet):\n","        selected_tweet = orig_selected[px]\n","        tweet_sentiment = sentiment[px]\n","        jaccard_score, _ = calculate_jaccard_score(\n","            original_tweet=tweet,\n","            target_string=selected_tweet,\n","            sentiment_val=tweet_sentiment,\n","            idx_start=np.argmax(outputs_start[px, :]),\n","            idx_end=np.argmax(outputs_end[px, :]),\n","            offsets=offsets[px]\n","        )\n","        jaccard_scores.append(jaccard_score)\n","\n","      jaccards.update(np.mean(jaccard_scores), ids.size(0))\n","      losses.update(loss.item(), ids.size(0))\n","      tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n","  \n","  print(f\"Jaccard = {jaccards.avg}\")\n","  return jaccards.avg"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZeDfkqe8AGdk","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"boCDYa0nAHB9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593884290020,"user_tz":300,"elapsed":5562,"user":{"displayName":"Abhishek Reddy Palle","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAOUr87agaYwb02gOAWZsxpouYO6t3YKRAuHZHqg=s64","userId":"04844477878113654498"}}},"source":["import pandas as pd\n","import torch.nn as nn\n","\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","def run(fold):\n","  utils.seed_everything(config.SEED)\n","  dfx = pd.read_csv(config.TRAIN_FILE)\n","\n","  df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n","  df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n","  \n","  ####################### Create Dataset and make it iterable #######################\n","  train_dataset = TweetDataset(\n","      tweets=df_train.text.values,\n","      sentiments=df_train.sentiment.values,\n","      selected_texts=df_train.selected_text.values\n","  )\n","\n","  train_data_loader = torch.utils.data.DataLoader(\n","      train_dataset,\n","      batch_size=config.TRAIN_BATCH_SIZE,\n","      num_workers=0 # Changed from 4 to 0 - Need further investigation\n","  )\n","\n","  valid_dataset = TweetDataset(\n","      tweets=df_valid.text.values,\n","      sentiments=df_valid.sentiment.values,\n","      selected_texts=df_valid.selected_text.values\n","  )\n","\n","  valid_data_loader = torch.utils.data.DataLoader(\n","      valid_dataset,\n","      batch_size=config.VALID_BATCH_SIZE,\n","      num_workers=0 # Changed from 2 to 0 - Need further investigation\n","  )\n","  ##################################################################################\n","\n","  # Load Config\n","  device = torch.device(\"cuda\")\n","  model_config = CONFIG_CLASS.from_pretrained(config.MODEL_CONFIG_PATH)\n","  model_config.output_hidden_states = True\n","  model = TweetModel(conf=model_config)\n","  model.to(device)\n","\n","  num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n","  param_optimizer = list(model.named_parameters())\n","  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","  optimizer_parameters = [\n","      {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","      {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n","  ]\n","  optimizer = AdamW(optimizer_parameters, lr=3e-5)\n","  scheduler = get_linear_schedule_with_warmup(\n","      optimizer, \n","      num_warmup_steps=0, \n","      num_training_steps=num_train_steps\n","  )\n","\n","  # Patience can be set to 4\n","  es = utils.EarlyStopping(patience=config.PATIENCE, mode=\"max\", delta=config.EARLY_STOPPING_DELTA)\n","  print(f\"Training is Starting for fold={fold}\")\n","\n","  # I'm training for EPOCHS epochs!!!\n","  for epoch in range(config.EPOCHS):\n","    train_fn(train_data_loader, model, optimizer, device, scheduler=scheduler)\n","    jaccard = eval_fn(valid_data_loader, model, device)\n","    print(f\"Jaccard Score = {jaccard}\")\n","    es(jaccard, model, model_path=f\"{config.SAVE_WEIGHTS_PATH}/model_{fold}.bin\")\n","    if es.early_stop:\n","        print(\"Early stopping\")\n","        break"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6Fllwe16RFT","colab_type":"code","colab":{}},"source":["run(fold=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hq8IEAGyGboE","colab_type":"code","colab":{}},"source":["run(fold=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_SvsKKjGb9T","colab_type":"code","colab":{}},"source":["run(fold=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjwvfuy3Gc1S","colab_type":"code","colab":{}},"source":["run(fold=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N819bPwIGdoC","colab_type":"code","colab":{}},"source":["run(fold=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Eu3WFx12PV-S","colab_type":"text"},"source":["# Do the evaluation on test data\n","\n"]},{"cell_type":"code","metadata":{"id":"6rfaiynvPWlA","colab_type":"code","colab":{}},"source":["df_test = pd.read_csv(config.TEST_FILE)\n","df_test.loc[:, \"selected_text\"] = df_test.text.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8nbR2_Ua3Vx","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\")\n","model_config = CONFIG_CLASS.from_pretrained(config.MODEL_CONFIG_PATH)\n","model_config.output_hidden_states = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BAmxQOU8a3S5","colab_type":"code","colab":{}},"source":["fold_models = []\n","for i in range(config.N_FOLDS):\n","  model = TweetModel(conf=model_config)\n","  model.to(device)\n","  model.load_state_dict(torch.load(f'{config.SAVE_WEIGHTS_PATH}/model_{i}.bin'))\n","  model.eval()\n","  fold_models.append(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMX42cxka3MV","colab_type":"code","colab":{}},"source":["final_output = []\n","\n","test_dataset = TweetDataset(\n","        tweets=df_test.text.values,\n","        sentiments=df_test.sentiment.values,\n","        selected_texts=df_test.selected_text.values)\n","\n","data_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    shuffle=False,\n","    batch_size=config.VALID_BATCH_SIZE,\n","    num_workers=0)\n","\n","with torch.no_grad():\n","  tk0 = tqdm(data_loader, total=len(data_loader))\n","  for bi, d in enumerate(tk0):\n","\n","    ids = d[\"ids\"]\n","    mask = d[\"mask\"]\n","    token_type_ids = d[\"token_type_ids\"]\n","    start_labels = d[\"start_labels\"]\n","    end_labels = d[\"end_labels\"]\n","    orig_tweet = d[\"orig_tweet\"]\n","    orig_selected = d[\"orig_selected\"]\n","    sentiment = d[\"sentiment\"]\n","    offsets = d[\"offsets\"]\n","\n","    ids = ids.to(device, dtype=torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n","    mask = mask.to(device, dtype=torch.long)\n","    start_labels = start_labels.to(device, dtype=torch.long)\n","    end_labels = end_labels.to(device, dtype=torch.long)\n","\n","    outputs_start_folds = []\n","    outputs_end_folds = []\n","    for i in range(config.N_FOLDS):\n","      outputs_start, outputs_end = fold_models[i](ids=ids,\n","                                                  mask=mask,\n","                                                  token_type_ids=token_type_ids)\n","      outputs_start_folds.append(outputs_start)\n","      outputs_end_folds.append(outputs_end)\n","\n","    outputs_start = sum(outputs_start_folds) / config.N_FOLDS\n","    outputs_end = sum(outputs_end_folds) / config.N_FOLDS\n","    \n","    outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n","    outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n","\n","    for px, tweet in enumerate(orig_tweet):\n","      selected_tweet = orig_selected[px]\n","      tweet_sentiment = sentiment[px]\n","      _, output_sentence = calculate_jaccard_score(\n","          original_tweet=tweet,\n","          target_string=selected_tweet,\n","          sentiment_val=tweet_sentiment,\n","          idx_start=np.argmax(outputs_start[px, :]),\n","          idx_end=np.argmax(outputs_end[px, :]),\n","          offsets=offsets[px]\n","      )\n","      final_output.append(output_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"usdIONUgfX13","colab_type":"code","colab":{}},"source":["# post-process trick:\n","# Note: This trick comes from: https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/140942\n","# When the LB resets, this trick won't help\n","def post_process(selected):\n","    return \" \".join(set(selected.lower().split()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdGrSAfQdtoF","colab_type":"code","colab":{}},"source":["sample = pd.read_csv(config.SAMPLE_SUBMISSION_FILE)\n","sample.loc[:, 'selected_text'] = final_output\n","sample.selected_text = sample.selected_text.map(post_process)\n","sample.to_csv(config.FINAL_SUBMISSION_FILE + '/submission.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZdmSD2zrdu_j","colab_type":"code","colab":{}},"source":["sample.head()"],"execution_count":null,"outputs":[]}]}